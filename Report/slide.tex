\documentclass{beamer}

%\usepackage[utf8x]{inputenc}


\usepackage{default}
%\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amsthm, amsfonts, amssymb}%fortmattazione teoremi, ecc
\usepackage{bbm}%simboli degli insiemi
\usepackage{mathrsfs}%fornisce un \mathscr, alternativo a \mathcal

\usepackage{fancybox}

%\usepackage{biblatex}


\usepackage{listings} %Per inserire codice
%\usepackage[usenames]{color} 
\usepackage{color}

%\definecolor{mygreen}{rgb}{0,0.6,0}

\usepackage{graphicx}

\usepackage{tikz}
\usetikzlibrary{trees,matrix,snakes}

%%%
%Definizione nuovi comandi
%%%
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}

% %NARE, CARE, ecc.
% \newcommand{\nare}{\mathrm{NARE}}
% \newcommand{\care}{\mathrm{CARE}}
% \newcommand{\gcare}{\mathrm{GCARE}}
% \newcommand{\mnare}{\mathsf{M}-\mathrm{NARE}}
% \newcommand{\adi}{\mathrm{ADI}}
% \newcommand{\cfadi}{\mathrm{C}\mathrm{f}-\mathrm{ADI}}
% \newcommand{\fadi}{\mathrm{f}-\mathrm{ADI}}

%trasposta:
\newcommand{\tras}[1]{#1^{\mathrm{T}}}
%trasposta e coniugata
\newcommand{\trasCon}[1]{#1^{\mathrm{*}}}
%Funzioni ad hoc
\newcommand{\effe}[2]{\mathcal{F}_{#1}(#2)}
\newcommand{\g}[2]{\mathcal{G}_{#1,#2}}

%puntini in diagonale inversa
\newcommand{\iddots}{\reflectbox{$\ddots$}}

%determinante dimensione, rango ecc.
\newcommand{\deter}[1]{\mathrm{det}(#1)} 
\newcommand{\rk}[1]{\mathrm{rk}(#1)}
\newcommand{\Dim}[1]{\mathrm{dim}(#1)}
\newcommand{\imminv}[1]{\mathrm{Im}^{-1}(#1)}


%tale che
% \newcommand{\tc}{ $\text{ } tale che \text{ }$ }
\newcommand{\tc}{ $ such that $ }

%Stile delle def, teo, prop, lem, ecc.
\theoremstyle{definition} \newtheorem{de}{Def}
\theoremstyle{remark} \newtheorem{os}[de]{Remark}
\theoremstyle{plain} \newtheorem{te}[de]{Teo}
\theoremstyle{plain} \newtheorem{co}[de]{Cor}
\theoremstyle{plain} \newtheorem{pr}[de]{Prop}
\theoremstyle{plain} \newtheorem{lem}[de]{Lemm}
\theoremstyle{remark} \newtheorem{rem}[de]{Remark}


%%%
%Stile: codice FORTRAN90
%%%

\lstdefinestyle{fortranSlide}{
  basicstyle=\footnotesize,
  numbers=left,
  numbersep=5pt,
  keywordstyle=\color{blue},
  commentstyle=\color{green},
  captionpos=b,
  frame=single,
  escapeinside={\!*}{*)},
  language=Fortran,
  caption=\lstname
}



%%%
%%%
%%%
\usetheme{default}
\usecolortheme{dolphin}
%\usetheme{Antibes}
%\usepackage{iwona}
%\beamertemplatetransparentcovereddynamicmedium
%\beamertemplateshadingbackground{blue!12}{white}
%\setbeamertemplate{navigation symbols}{}
%%%
%%%
%%%
\title{An Algorithm for the \\
Generalized Symmetric Tridiagonal \\
Eigenvalue Problem}
\subtitle{Kuiyuam Li, Tien-Yien Li, Zhonggang Zeng}
\author{Giulio Masetti}
\institute{Universit\`a di Pisa\\
Metodi di Approssimazione 2012-2013
}
\date{\today}

%%%
%%%
%%%
\begin{document}


\long\def\symbolfootnote[#1]#2{\begingroup%
\def\thefootnote{\fnsymbol{footnote}}\footnote[#1]{#2}\endgroup} 

\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=red,fill=red!30]
\tikzstyle{optional}=[dashed,fill=gray!50]

\newenvironment{fminipage}%
{\begin{Sbox}\begin{minipage}}%
{\end{minipage}
\end{Sbox}
\fbox{\TheSbox}}

\begin{frame}
  \titlepage
\end{frame}


\section{Contents}

\begin{frame} 
\frametitle{Generalized Eigenvalue Problem}  

\begin{de}
  $T,S\in\R^{n\times n}$. We call $(T,S)$ \emph{pencil}.
\end{de}

We consider \emph{only} \begin{fminipage}{0.8in} symmetric \\ and \\ 
tridiagonal\end{fminipage} pencils.

\pause

$S$ is \textcolor{blue}{\emph{positive definite}}.

\pause

\begin{de}[Problem]
  Find $\lambda\in\R \tc T v = \lambda S v$, with $v\in\C^n$. \\
  $T,S$ symmetric implies $\lambda\in\R$.
\end{de}
\end{frame}

\begin{frame}
\frametitle{Algorithm philosophy}

We find zeros of the polynomial equation

\begin{equation*}
  \effe{(T,S)}{\lambda} = \deter{T-\lambda S} = 0
\end{equation*}

using an iterative method, living on real line.
\end{frame}

\section{Ideas and tecnology}

\begin{frame}
\frametitle{Brainstorming}

\begin{Bdescription}
  \item [We want:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Fast and secure iterative method.
  \item Starting points for our method.
  \item Scalability.
  \end{Bitemize}}
  
  \item [We have:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Laguerre's method.
  \item Cuppen's divide and conquer method.
  \item Symmetric tridiagonal matrices.
  \end{Bitemize}}

  \item [We add:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Unreducible condition.
  \item Dynamic programming (Bottom-up).
  \item Efficient matrix storing.
  \end{Bitemize}}
\end{Bdescription}
\end{frame}

\subsection{Rapid tour}

\begin{frame}
\frametitle{Rapid tour}

\begin{Bdescription}
  \item [We want:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Fast and secure iterative method.
  \item Starting points for our method.
  \item Scalability.
  \end{Bitemize}}
  
  \item [We have:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Laguerre's method.
  \item Cuppen's divide and conquer method.
  \item \textcolor{blue}{Symmetric tridiagonal matrices}.
  \end{Bitemize}}

  \item [We add:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item \textcolor{blue}{Unreducible condition}.
  \item Dynamic programming (Bottom-up).
  \item \textcolor{blue}{Efficient matrix storing}.
  \end{Bitemize}}
\end{Bdescription}
\end{frame}


\begin{frame}
\frametitle{Unreducible pencil}

\begin{de}[ as in \cite{principal} ]
  $(T,S)$ is an \emph{unreducible pencil} if $t_{i,i+1}^2 + 
s_{i,i+1}^2 \neq 0$\\
  for $i=1,2,\dots,n-1$.
\end{de}

\pause

\emph{exempli gratia}:

\begin{Bdescription}
  \item [\textcolor{red}{Bad}]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item $T=I,S=0$
  \item $T=I,S=I$
  \end{Bitemize}}
  
  \item [\textcolor{green}{Good}]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item $T=I,S=trid(-1,2,-1)$
  \item $T=trid(-1,2,-1),S=trid(-1,2,-1)$
  \item $T=trid(rnd_{sub},rnd_{diag},rnd_{sub}),S=I$,\\ 
    with $rnd_{sub}$ random number $\ne 0$.
  \end{Bitemize}}
\end{Bdescription}

\end{frame}

\begin{frame}[fragile]
\frametitle{Matrix storing}

\begin{equation*}
  T = trid(sub,diag,super)
\end{equation*}

But $T$ is symmetric, so $sub=super$. We define and use

\begin{lstlisting}[style=fortranSlide, caption={$T,S$ as couple of array}]
  integer, parameter :: dp = kind(1.d0)
  real(dp), dimension(1:n,0:1) :: T, S  
\end{lstlisting}

with $T(:,0)=diag$ and $T(:,1)=super$.

\begin{os}
  We don't use T(1,1) and S(1,1). 
\end{os}

\end{frame}

\section{Laguerre's method}

\begin{frame}
\frametitle{Fast and secure iterative method}

\begin{Bdescription}
  \item [We want:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item \textcolor{blue}{Fast and secure iterative method}.
  \item Starting points for our method.
  \item Scalability.
  \end{Bitemize}}
  
  \item [We have:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item \textcolor{blue}{Laguerre's method}.
  \item Cuppen's divide and conquer method.
  \item Symmetric tridiagonal matrices.
  \end{Bitemize}}

  \item [We add:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Unreducible condition.
  \item Dynamic programming (Bottom-up).
  \item Efficient matrix storing.
  \end{Bitemize}}
\end{Bdescription}
\end{frame}


\begin{frame}
\frametitle{Fast and secure iterative method}

$\effe{T,S}{\lambda}$ is a polynomial with only real zeros; we call them
\begin{equation*}
  \lambda_1 \le \lambda_2 \le \dots \le \lambda_n
\end{equation*}

where we count with multiplicity.\\ 

\pause 

If $\lambda_m$ and $\lambda_{m+1}$ are simple zeros (mlt=1), then we consider $x$ between them and the quadric

\pause

\begin{equation*}
  g_{u}(X) = (x-X)^2 \sum_{i=1}^n \frac{(u-\lambda_i)^2}{(x-\lambda_i)^2} - (u-X)^2
\end{equation*}

\pause

if $\fbox{$u\neq x$}$ then $g_{u}(x)<0$ and $g_u(\lambda_m),g_u(\lambda_{m+1})>0$. \\
So we have two sign changes. \\

\pause

Bolzano's Theorem tell us that there are two zeros of $g_{u}$ between $\lambda_m$ and $\lambda_{m+1}$. We call them $X_{-},X_{+}$.

\end{frame}

\begin{frame}
\frametitle{Fast and secure iterative method}

\begin{equation*}
  \lambda_m < X_{-} < x < X_{+} < \lambda_{m+1}
\end{equation*}

We have one freedom: the $u$ parameter. \\
Calling $\hat X_{-}=min_{u} X_{-}$ and $\hat X_{+}=max_{u} X_{+}$  we can obtain


\begin{equation*}
  \lambda_m \approx \hat X_{-} < x < \hat X_{+} \approx \lambda_{m+1}
\end{equation*}

and with algebraic manipulations: 

\begin{equation*}
  \hat X_{-}, \hat X_{+} = L_{\pm}(x) = x + \frac{ n }{ -\frac{f^{'}}{f} \pm \sqrt{(n-1)[ (n-1)(-\frac{f^{'}}{f}) -n\frac{f^{''}}{f} ]} }
\end{equation*}

with $\frac{f^{'}}{f}=\frac{ (\effe{T,S}{\lambda})^{'} }{ \effe{T,S}{\lambda} }$. 

\end{frame}


\begin{frame}
  \frametitle{Fast and secure iterative method}
  So we need \textcolor{blue}{$\frac{f^{'}}{f}$} and \textcolor{blue}{$\frac{f^{''}}{f}$}. \\

\pause

This is one of the most important aspect of our calculation. \\

\pause

We will see that ``only'' with the \textcolor{blue}{symmetric tridiagonal} condition we can have \textcolor{green}{derivatives of determinats}.
\end{frame}


\begin{frame}
\frametitle{Fast and secure iterative method}

It's clear how we use $\lambda_m \approx \hat X_{-} < x < \hat X_{+} \approx \lambda_{m+1}$ :

\begin{tikzpicture}
 \draw[->] (-1.5,0) -- (5.5,0); 
 \node[circle, fill=black!1, label=above:$x_{0}$] at (2.5,0) {};
 \uncover<2>{
   \node[circle, fill=black!1, label=above:$x^{(1)}_{-}$] at (1,0) {};
   \node[circle, fill=black!1, label=above:$x^{(1)}_{+}$] at (3.5,0) {};
 }
 \uncover<3>{
   \node[circle, fill=black!1, label=above:$x^{(2)}_{-}$] at (-0.2,0) {};
   \node[circle, fill=black!1, label=above:$x^{(2)}_{+}$] at (3.9,0) {};
   }
 \uncover<4>{
   \node[circle, fill=black!1, label=above:$\lambda_{m}$] at (-.5,0) {};
   \node[circle, fill=black!1, label=above:$\lambda_{m+1}$] at (4,0) {};
 }
\end{tikzpicture}

\end{frame}



\begin{frame}[label=BeforeLagProof]
\frametitle{Fast and secure iterative method}

\begin{de}[Laguerre's iteration]
  \textcolor{blue}{If} $mlt(\lambda_m)=mlt(\lambda_{m+1})=1$ \textcolor{blue}{then}
  \begin{align*}
    x_{+}^{(k)} &= L_{+}^k(x)=L_{+}(L_{+}(\dots(x_{0})))\\
    x_{-}^{(k)} &= L_{-}^k(x)=L_{-}(L_{-}(\dots(x_{0})))
  \end{align*}
  \textcolor{blue}{else} we have another similar expression.
\end{de} 

\pause

\hyperlink{LagProof}{\beamergotobutton{proof}} We can prove that

\begin{equation*}
  \lambda_m \leftarrow \dots x_{-}^{(2)} < x_{-}^{(1)} < x_{0} < x_{+}^{(1)} < x_{+}^{(2)} \dots \rightarrow \lambda_{m+1}
\end{equation*}
  
\pause

So Laguerre's method is \textcolor{green}{secure}.

\end{frame}

%%%
%DIMOSTRAZIONE
%%%

\begin{frame}
\frametitle{Fast and secure iterative method}

We also have un important property:

\begin{te}
  If we choose\symbolfootnote[1]{ for $x_0 < \lambda_{m+1}$ s.t. 
$sign \Big( \frac{f^{'}(x_0)}{f(x_0)} \Big) = sign(\lambda_m - x_0)$ we have 
$\{ x_{+}^{(k)} \}_{k=1,\dots}$ conv. mon. cubic to $\lambda_{m+1}$ } $\lambda_m < x_0$ s.t. 
$sign \Big( \frac{f^{'}(x_0)}{f(x_0)} \Big) = sign(\lambda_m - x_0)$ then 
$\{ x_{-}^{(k)} \}_{k=1,\dots}$ converges monotonically in asymptotically 
cubic rate to $\lambda_m$. 
\end{te}

\pause

So we can exactly define a $\fbox{neighborhood ``near'' $\lambda$ }$ and in it we
have cubic rate convergence (much, much faster then \textcolor{red}{simple bisection}) 

\pause

\begin{tikzpicture}
  \draw (0,0) [fill=yellow] ellipse (2cm and 1cm);
  \draw[->] (-5,0) -- (5,0);
  \node[circle, fill=black, label=above:$\lambda_m$] at (-.5,0) {};
  \node[circle,fill=black!,label={[xshift=4cm, yshift=-1.5cm] $sign \Big( \frac{f^{'}}{f} \Big) \text{ eq } sign(\lambda_m - x_0)$}] at (-.5,0) {};
  \node[circle, fill=black!1, label=above:$x_{0}$] at (1.25,0) {};
\end{tikzpicture}

\pause

The Laguerre's method is \textcolor{green}{fast}.

\end{frame}


\begin{frame}
\frametitle{Fast and secure iterative method}

It's clear that we need a powerfull method to obtain $x_{0}$ and an algorithm to 
estimate $mlt(\lambda_m)$. \\
\emph{Overstimate} $mlt(\lambda_m)$ (as we can read in \cite{secondary}) causes no trouble, so the most important aspects of our calculation are: 

\fbox{\setlength{\itemsep}{0pt}
\begin{Bitemize}[t]
\item Good $x_{0}$.
\item Good evaluation of $L_{\pm}(x)$.
\end{Bitemize}}

\end{frame}

\begin{frame}[label=Julia]
  \frametitle{Complex case (little digression)}

  According to \cite{julia}, we observe that with Laguerre's method searching $z\in\C \tc z^n - 1 = 0$ for $n>4$ it's difficult because near the origin there is a Julia fractal set for starting point $z_0$. (figure: $n=6$)

\begin{figure}
  \centering
  \includegraphics[scale=0.3]{images/JuliaLaguerre.pdf}
  %\caption{Julia set for $z^6 -1 =0$}
\end{figure}

\pause

So if we want to solve the Generalized Eigenvalues Problem with $T,S\in\textcolor{blue}{\C}$ we have \textcolor{red}{great problems} to place the starting point if $n>4$. 

\end{frame}

\section{Good evaluation of $L_{\pm}(x)$}

\begin{frame}
  \frametitle{Three-term recurrence}
  For a generic $x\in\R$ we call $\rho_n(x) = \deter{T_n-x S_n}$,
  and $\rho_{n-1}(x) = \deter{T_{n-1}-x S_{n-1}}$, with $T_{n-1}$ leading principal submatrix. 

  We have

  \begin{align*}
    \rho_0 &:= 1\, \text{, } \rho_1:=t_{1,1}- x s_{1,1} \\
    \rho_i &:= (t_{i,i}- x s_{i,i})\textcolor{blue}{\rho_{i-1}} - (t_{i-1,i}-x s_{i-1,i})^2 \textcolor{cyan}{\rho_{i-2}}\, \text{, } i=2,3,\dots,n
  \end{align*}

\end{frame}

\begin{frame}
  \frametitle{Three-term recurrence}

  We can proove it with the \emph{Laplace expansion} (e.g. $n=4$)

  \begin{align*}
    T_4 - x S_4  &= \begin{pmatrix} 
      a & b & 0 & \textcolor{green}{0}\\
      b & c & d & \textcolor{green}{0}\\
      0 & d & e & \textcolor{green}{f}\\
      0 & 0 & f & \textcolor{green}{g}
    \end{pmatrix} \\
    det \Big( T_4 - \lambda S_4 \Big) &= g \begin{bmatrix}
      a & b & 0\\
      b & c & d\\
      0 & d & e
    \end{bmatrix} -f \begin{bmatrix}
      a & b & 0\\
      b & c & d\\
      \textcolor{green}{0} & \textcolor{green}{0} & \textcolor{green}{f}
    \end{bmatrix}\\
    &= g \begin{bmatrix} 
      a & b & 0\\
      b & c & d\\
      0 & d & e
    \end{bmatrix} - f^2 \begin{bmatrix} a & b \\ b & c \end{bmatrix}
  \end{align*}

\end{frame}

\begin{frame}
  \frametitle{Three-term recurrence}

  We can proove it with the \emph{Laplace expansion} (e.g. $n=4$)

  \begin{align*}
    T_4 - x S_4  &= \begin{pmatrix} 
      \textcolor{cyan}{a} & \textcolor{cyan}{b} & \textcolor{blue}{0} & 0\\
      \textcolor{cyan}{b} & \textcolor{cyan}{c} & \textcolor{blue}{d} & 0\\
      \textcolor{blue}{0} & \textcolor{blue}{d} & \textcolor{blue}{e} & f\\
      0 & 0 & f & g
    \end{pmatrix} \\
    det \Big( T_4 - \lambda S_4 \Big) &= g \begin{bmatrix}
      \textcolor{cyan}{a} & \textcolor{cyan}{b} & \textcolor{blue}{0}\\
      \textcolor{cyan}{b} & \textcolor{cyan}{c} & \textcolor{blue}{d}\\
      \textcolor{blue}{0} & \textcolor{blue}{d} & \textcolor{blue}{e}
    \end{bmatrix} -f \begin{bmatrix}
      \textcolor{cyan}{a} & \textcolor{cyan}{b} & 0\\
      \textcolor{cyan}{b} & \textcolor{cyan}{c} & d\\
      0 & 0 & f
    \end{bmatrix}\\
    &= g \begin{bmatrix} 
      \textcolor{cyan}{a} & \textcolor{cyan}{b} & \textcolor{blue}{0}\\
      \textcolor{cyan}{b} & \textcolor{cyan}{c} & \textcolor{blue}{d}\\
      \textcolor{blue}{0} & \textcolor{blue}{d} & \textcolor{blue}{e}
    \end{bmatrix} - f^2 \begin{bmatrix} 
      \textcolor{cyan}{a} & \textcolor{cyan}{b} \\ 
      \textcolor{cyan}{b} & \textcolor{cyan}{c} 
    \end{bmatrix}
  \end{align*}

\end{frame}


\begin{frame}[label=BeforeSturmSequence]
  \frametitle{Three-term recurrence}

  \begin{os}
    If $x = \lambda$ then $\rho_n(\lambda)=\effe{(T_n,S_n)}{\lambda}=f(\lambda)$
  \end{os}

  \begin{os}[ important results with \hyperlink{SturmSequence}{\beamergotobutton{proof}} in Appendix]
    $\rho_0,\rho_1,\dots,\rho_n$ is a \textcolor{blue}{\emph{Sturm sequence}} of polynomials so, $\forall x\in\R$, we have

    \begin{align*}
      \kappa(x) &:= \text{\# eigenvalues less then } x \\
      \kappa(x) &= \textcolor{blue}{ \text{\# consecutive sign changes in } \{ \rho_i \}_{i=0,\dots,n} }
    \end{align*}
  \end{os}

  \begin{tikzpicture}
    \draw[->] (-5,0) -- (4,0);
    \node[circle, fill=black!1, label=above:$\lambda_1$] at (-4,0) {};
    \node[circle, fill=black!1, label=above:$\lambda_2$] at (-3,0) {};
    \node[circle, fill=black!1, label=above:$\lambda_3$] at (-2,0) {};
    \node[circle, fill=black!1, label=above:$\lambda_4$] at (-1,0) {};
    \node[circle, fill=green, label=above:$x$] at (0,0) {};
    \node[circle, fill=green, label=below:$\kappa(x)\text{ is } 4$] at (0,0) {};
    \node[circle, fill=black!1, label=above:$\lambda_5$] at (1,0) {};
    \node[circle, fill=black!1, label=above:$\lambda_6$] at (2,0) {};
  \end{tikzpicture}
  
\end{frame}

\begin{frame}
  \frametitle{Three-term recurrence}

  Obviusly $f^{'}=\rho_n^{'},f^{''}=\rho_n^{''}$.


  %If .\\
  %If $\kappa(x)< m$ then $sign(\lambda_m -x)=\textcolor{blue}{+}$.

  \pause

  So\symbolfootnote[1]{$\kappa(x)< m$ implies $sign(\lambda_m -x)=\textcolor{blue}{+}$} 
  \begin{equation*}
    \textcolor{blue}{\text{IF }} \Big( \kappa(x_0)\ge m \textcolor{cyan}{\text{ AND }} -\frac{f^{'}}{f}< 0 \Big) \textcolor{cyan}{\text{ OR }} \Big( \kappa(x_0) < m \textcolor{cyan}{\text{ AND }} -\frac{f^{'}}{f}\ge 0 \Big) \textcolor{blue}{\text{ THEN }}
  \end{equation*}

  \pause

  We have \textcolor{blue}{cubic convergence} in Laguerre's method with $x_0$ as starting point.

\end{frame}



\begin{frame}
  \frametitle{Example}

  \begin{tikzpicture}
    \uncover<3,4,5>{\draw (1,0) [fill=yellow] ellipse (1cm and .5cm);}
    \draw[->] (-5,0) -- (5,0);
    \uncover<5>{\node[circle, fill=black, label=above:$\lambda_m$] at (.5,0) {};}
    \uncover<1,2,3>{\node[circle, fill=black!1, label=above:initial point] at (4,0) {};}
    \uncover<2>{
      \node[circle, fill=black!1, label=below:$\kappa$ is $m$] at (4,0) {};
      \node[circle, fill=black!1, label=below:$\kappa$ is $m-1$] at (-4,0) {};
    }
    \uncover<3>{
      \draw (-4,-.2) -- (-4,.2);
      \draw (0,-.2) -- (0,.2);
      \draw (2,-.2) -- (2,.2);
      %\draw (1,-.2) -- (1,.2);
      \node[draw=none, label={[yshift=-1.5cm] with \textcolor{blue}{bisection} we can find the neighbourhood of $\lambda_m$}] at (0,0) {};
    }
    \uncover<4>{
      \node[draw=none, label={[xshift=-3cm, yshift=2cm] we can now use the Laguerre's iteration}] at (1.5,0) {};
    }
    \uncover<4,5>{
      \node[circle, fill=black!1, label=above:$x_0$] at (1.5,0) {};
    }
  \end{tikzpicture}

\end{frame}

\begin{frame}
  \frametitle{What we really calculate is...}

  We \textcolor{blue}{define} $\xi_i=\frac{\rho_i}{\rho_{i-1}}$ for $i=2,\dots, n$ and we have $\rho_i=\prod_{k=1}^{i} \xi_k$.

  \pause

  We also \textcolor{blue}{define} $\eta_i=\frac{\rho^{'}_i}{\rho_i}, \zeta_i=\frac{\rho^{''}_i}{\rho_i}$ for $i=0,1,\dots,n$ and finally we have

  \begin{align*}
    \kappa(x) &= \text{ number of \textcolor{blue}{negative terms} in } \{ \xi_i \}_{i=1}^{n} \\
    - \frac{f^{'}(x)}{f(x)} &= \eta_n \\
    \frac{f^{''}(x)}{f(x)} &= \zeta_n
  \end{align*}
  
\end{frame}

\begin{frame}
  \frametitle{What we really calculate is...}

  So we have to calculate three three-term recurrences.
  
  \pause

  \symbolfootnote[1]{we consider all elements of diag and super of $(T,S)$ as non zero.} Total $\le 2 + 38n$ multiplications.

  \pause

  For every step in Laguerre's iteration we have to do $2 + 7 + 38n$ (at most) multiplications and $1$ square root extraction. Because the convergence is cubic we \textcolor{green}{hope} in a small number of iteration.

\end{frame}

\begin{frame}
  \frametitle{Complexity}

  \symbolfootnote[1]{They use $n<100$, \\ my experiment ends up with $n=2^{13}=8192$.}Author's prevision: $O(n^2)$.\\
  With $(I,S)$ and eigenvalues between $0.5$ and $1.5$ we have

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/Tempi_con_riferimento_quadrato_13.pdf}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}
  
\end{frame}

\begin{frame}
  \frametitle{Complexity}

  And in linear scale:

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/Tempi_13.pdf}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

\end{frame}

\begin{frame}
  \frametitle{Complexity}
  With $T=(a_i,1,a_i),S=(b_i, c_i ,b_i)$ and $a_i, b_i$ random numbers $\tc |a_i|\le 10^{-3}, |b_i|\le 10^{-1}, c_i = i 10^{-1} + |2 b_i|$ we have

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/Tempi_con_riferimento_quadrato_13_matrici_complete.pdf}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

We can appreciate little differences between $T=(0,1,0)$ and $T=(a_i,1,a_i)$

\end{frame}

%%%
%%%
%%%

\section{Error Analysis}

\begin{frame}
  \frametitle{Error Analysis}

It's known that three-term recurrences suffer from severe overflow and underflow problems, and because of that we use $\xi_i$ instead of $\rho_i$: 

\pause

\textcolor{blue}{$\xi_i=\frac{\rho_i}{\rho_{i-1}}$,it's \emph{self-scaled}}.

\pause

\begin{te}
  \begin{equation*}
    \text{fl}[f(x)] = \text{fl}[\text{det}[\textcolor{blue}{T}-x\textcolor{blue}{S}]] = (1 + \gamma)\text{det}[(\textcolor{cyan}{T+ \delta T}) -x(\textcolor{cyan}{S + \delta S})]
  \end{equation*}
  where $|\gamma|\le n\epsilon$, with $\epsilon$ machine precision, and both $\delta T$ and $\delta S$ are symmetric tridiagonal matrices satisfying entrywise inequalities $|\delta T|_{\infty}\le 2.51\epsilon |T|_{\infty} + \sqrt{\epsilon_u}, |\delta S|_{\infty}\le 3.51\epsilon |S|_{\infty}$, where $\epsilon_u$ is the underflow threshold (in double precision is $10^{-308}$).
\end{te}

\end{frame}

\begin{frame}
  \frametitle{Error Analysis}

We are interested not only in $\text{fl}[f(x)]=\text{fl}\Big[ \prod_{i=1}^n \text{fl}[\xi_i]  \Big]$, but also in $\text{fl}[\eta_n]$ and $\text{fl}[\zeta_n]$, because we use these three value to calculate the Laguerre's iteration.

\pause

\textcolor{red}{The authors don't report this important aspect of analysis}.

\pause

($\text{fl}[\eta_n],\text{fl}[\zeta_n]$ suffer from similar problems and have similar backward analysis, but they are -in partucular $\zeta_n$- enourmous in magnitude; sometimes this can cause troubles)

\end{frame}

\begin{frame}
  \frametitle{Exponent of absolute error ($n=256$)}
  With $(I,S)$ and eigenvalue between $0.5$ and $1.5$ we have

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/IstogrammaEsponentiErrori_256.pdf}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

\end{frame}


\begin{frame}
  \frametitle{Where is the problem?}

   Sometimes (about $3$ over $100$ eigenvalues with $n \ge 256$) Laguerre's iteration \textcolor{red}{breaks the monotonic convergence}! 

   \pause

   In these cases we have slower convergence and greater error.

   \pause

   I think the problem is in $\kappa,\eta_n,\zeta_n$. \\ Sometimes, when $|\lambda_j - x_0|\le 10^{-4}$ and $(T,S)$ have small elements, we can have troubles.

   \pause

   If we compare $\kappa(x_i)$ and the same number \textcolor{blue}{obtained with \emph{inertia}} for $|\lambda_j - x_i|\le 10^{-i}$ and $i=1,\dots,16$ we have
 
\end{frame}

\begin{frame}

  $n=256$, $\text{dim}=64$ and pencil=$(T(193:4\text{dim}),S(193:4\text{dim}))$

  \frametitle{Where is the problem?}
  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/ConfrontoLagItInerziaKappa.pdf}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

For $i=1,\dots,16$, \textcolor{purple}{absolute errors between $\lambda_{32}$ and $x_i$ with $\kappa$}, \textcolor{black}{absolute errors between $\lambda_{32}$ and $x_i$ with \emph{inertia}}.

\end{frame}

\begin{frame}
  \frametitle{Where is the problem?}

  $n=256$, $\text{dim}=64$ and pencil=$(T(193:4\text{dim}),S(193:4\text{dim}))$

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/ConfrontoLagItInerziaKappa_scala_logaritmica_reciproco.pdf}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

For $i=1,\dots,16$, \textcolor{purple}{absolute errors between $\lambda_{32}$ and $x_i$ with $\kappa$}, \textcolor{black}{absolute errors between $\lambda_{32}$ and $x_i$ with \emph{inertia}}. \\
\textcolor{blue}{I use a different scale: $log(\frac{1}{|error|})$}

\end{frame}

\begin{frame}
  \frametitle{Where is the problem?}

  When $x_0$ for Laguerre's iteration is into our \textcolor{blue}{good neighbourhood} but $10^{-9} \le |x_0-\lambda_m|\le 10^{-1}$, we can have troubles...

  \pause

  Starting points are the most important aspect of our calculation.

\end{frame}

\section{Good initial point}

\begin{frame}
\frametitle{Searching initial points}

\begin{Bdescription}
  \item [We want:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Fast and secure iterative method.
  \item \textcolor{blue}{Starting points for our method}.
  \item Scalability.
  \end{Bitemize}}
  
  \item [We have:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Laguerre's method.
  \item \textcolor{blue}{Cuppen's divide and conquer method}.
  \item Symmetric tridiagonal matrices.
  \end{Bitemize}}

  \item [We add:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Unreducible condition.
  \item Dynamic programming (Bottom-up).
  \item Efficient matrix storing.
  \end{Bitemize}}
\end{Bdescription}
\end{frame}

\begin{frame}
  \frametitle{Ideas:}
  If $\textcolor{blue}{n=1}$ we have $t\cdot v=\lambda\cdot s\cdot v$ with $s\ne 0$, so 
  $\textcolor{blue}{\lambda= \frac{t}{s}}$.\\
  
  \pause
  
  If $\textcolor{blue}{n=2}$ we have $\begin{bmatrix}t_{1,1}&t_{1,2}\\ t_{2,1} & t_{2,2}\end{bmatrix} \begin{bmatrix}v_{1} \\ v_{2}\end{bmatrix} = \lambda \begin{bmatrix}s_{1,1} & s_{1,2}\\ s_{2,1} & s_{2,2}\end{bmatrix} \begin{bmatrix}v_{1} \\ v_{2}\end{bmatrix}$


\end{frame}


\begin{frame}
  \frametitle{Ideas:}
  If $\textcolor{blue}{n=1}$ we have $t\cdot v=\lambda\cdot s\cdot v$ with $s\ne 0$, so 
  $\textcolor{blue}{\lambda= \frac{t}{s}}$.\\
  
  If $\textcolor{blue}{n=2}$ we have $\begin{bmatrix}t_{1,1}&t_{1,2}\\ t_{2,1} & t_{2,2}\end{bmatrix} \begin{bmatrix}v_{1} \\ v_{2}\end{bmatrix} = \lambda \begin{bmatrix}s_{1,1} & s_{1,2}\\ s_{2,1} & s_{2,2}\end{bmatrix} \begin{bmatrix}v_{1} \\ v_{2}\end{bmatrix}$
  
  
  calling\symbolfootnote[1]{$\alpha=s_{2,2}t_{1,1}-s_{1,2}t_{1,2},\beta=-s_{1,2}t_{1,2}+s_{1,1}t_{2,2}$ \\ $\gamma=-s_{1,2}t_{1,2}+s_{1,1}t_{1,2}, \delta=s_{1,1}s_{2,2}-s_{1,2}^2$.} 

  \begin{equation*}
    S^{-1}T = \delta^{-1} \cdot \Big( \begin{matrix} \alpha & \gamma \\ \gamma & \beta \end{matrix}\Big)
  \end{equation*}

  we resolve $det[ S^{-1}T - \lambda I ]=0$ with

  \begin{equation*}
    \textcolor{blue}{\lambda_{1,2}} = \textcolor{blue}{\frac{1}{2\delta}  
  \big( \alpha+\beta \pm \sqrt{ \alpha^2 + \beta^2 + 
  \gamma^2 - \alpha\beta } \big)}
  \end{equation*}

\end{frame}

\begin{frame}
  \frametitle{Ideas:}

  And if $\textcolor{blue}{n=4}$?
  
  \begin{equation*}
    \begin{pmatrix}
      t_{1,1} & t_{1,2} & 0 & 0\\
      t_{2,1} & t_{2,2} & t_{2,3} & 0\\
      0 & t_{3,2} & t_{3,3} & t_{3,4}\\
      0 & 0 & t_{4,3} & t_{4,4}
    \end{pmatrix} \begin{pmatrix} 
      v_1 \\ 
      v_2 \\
      v_3 \\
      v_4
    \end{pmatrix} = \lambda \begin{pmatrix}
      s_{1,1} & s_{1,2} & 0 & 0\\
      s_{2,1} & s_{2,2} & s_{2,3} & 0\\
      0 & s_{3,2} & s_{3,3} & s_{3,4}\\
      0 & 0 & s_{4,3} & s_{4,4}
    \end{pmatrix} \begin{pmatrix}
      v_1 \\ 
      v_2 \\
      v_3 \\
      v_4
    \end{pmatrix}
  \end{equation*}

\end{frame}


\begin{frame}
  \frametitle{Ideas:}

  And if $\textcolor{blue}{n=4}$?
  
  \begin{equation*}
    \begin{pmatrix}
      \textcolor{blue}{t_{1,1}} & \textcolor{blue}{t_{1,2}} & 0 & 0\\
      \textcolor{blue}{t_{2,1}} & \textcolor{blue}{t_{2,2}} & t_{2,3} & 0\\
      0 & t_{3,2} & \textcolor{cyan}{t_{3,3}} & \textcolor{cyan}{t_{3,4}}\\
      0 & 0 & \textcolor{cyan}{t_{4,3}} & \textcolor{cyan}{t_{4,4}}
    \end{pmatrix} \begin{pmatrix} 
      \textcolor{blue}{v_1} \\ 
      \textcolor{blue}{v_2} \\
      \textcolor{cyan}{v_3} \\
      \textcolor{cyan}{v_4}
    \end{pmatrix} = \lambda \begin{pmatrix}
      \textcolor{blue}{s_{1,1}} & \textcolor{blue}{s_{1,2}} & 0 & 0\\
      \textcolor{blue}{s_{2,1}} & \textcolor{blue}{s_{2,2}} & s_{2,3} & 0\\
      0 & s_{3,2} & \textcolor{cyan}{s_{3,3}} & \textcolor{cyan}{s_{3,4}}\\
      0 & 0 & \textcolor{cyan}{s_{4,3}} & \textcolor{cyan}{s_{4,4}}
    \end{pmatrix} \begin{pmatrix}
      \textcolor{blue}{v_1} \\ 
      \textcolor{blue}{v_2} \\
      \textcolor{cyan}{v_3} \\
      \textcolor{cyan}{v_4}
    \end{pmatrix}
  \end{equation*}

\end{frame}


\begin{frame}
  \frametitle{Ideas:}

  And if $\textcolor{blue}{n=4}$?
  

  \begin{equation*}
    \begin{pmatrix}
      \textcolor{blue}{t_{1,1}} & \textcolor{blue}{t_{1,2}} & 0 & 0\\
      \textcolor{blue}{t_{2,1}} & \textcolor{blue}{t_{2,2}} & \textcolor{red}{0} & 0\\
      0 & \textcolor{red}{0} & \textcolor{cyan}{t_{3,3}} & \textcolor{cyan}{t_{3,4}}\\
      0 & 0 & \textcolor{cyan}{t_{4,3}} & \textcolor{cyan}{t_{4,4}}
    \end{pmatrix} \begin{pmatrix} 
      \textcolor{blue}{v_1} \\ 
      \textcolor{blue}{v_2} \\
      \textcolor{cyan}{v_3} \\
      \textcolor{cyan}{v_4}
    \end{pmatrix} = \lambda \begin{pmatrix}
      \textcolor{blue}{s_{1,1}} & \textcolor{blue}{s_{1,2}} & 0 & 0\\
      \textcolor{blue}{s_{2,1}} & \textcolor{blue}{s_{2,2}} & \textcolor{red}{0} & 0\\
      0 & \textcolor{red}{0} & \textcolor{cyan}{s_{3,3}} & \textcolor{cyan}{s_{3,4}}\\
      0 & 0 & \textcolor{cyan}{s_{4,3}} & \textcolor{cyan}{s_{4,4}}
    \end{pmatrix} \begin{pmatrix}
      \textcolor{blue}{v_1} \\ 
      \textcolor{blue}{v_2} \\
      \textcolor{cyan}{v_3} \\
      \textcolor{cyan}{v_4}
    \end{pmatrix}
  \end{equation*}


\pause


We can solve the \textcolor{blue}{blue} part and obtain $\textcolor{blue}{\mu_{1}},\textcolor{blue}{\mu_{2}}$, the \textcolor{cyan}{cyan} part and obtain $\textcolor{cyan}{\mu_{3}},\textcolor{cyan}{\mu_{4}}$.

\end{frame}


\begin{frame}[label=BeforeCodeIf]
  \frametitle{Ideas:}

From $\mu_j$ we can enter in our neighbourhood of $\lambda_j$ using simple \textcolor{blue}{bisection}:

\pause

\begin{Bdescription}
\item [Pseudocode:]
\fbox{\setlength{\itemsep}{0pt}
\begin{Bitemize}[t]
\item \textcolor{blue}{set} $a_j=0$ and $b_j=\mu_j$ 
\item \textcolor{blue}{set} $x=\mu_j$
\item \textcolor{cyan}{\#} \textcolor{blue}{IF} $\kappa(x)<j$ 
\item \textcolor{blue}{THEN} \textcolor{blue}{set} $a_j=x$ 
\item \textcolor{blue}{ELSE} \textcolor{blue}{set} $b_j=x$
\item \textcolor{blue}{\symbolfootnote[1]{This is an important part of our method. \\ Authors of \cite{principal, secondary} doesn't explain this point. \hyperlink{CodeIf}{\beamergotobutton{code}} }IF} $-\frac{f^{'}(x)}{f(x)}=sign(\lambda_j - x)$
\item \textcolor{blue}{THEN} \textcolor{blue}{stop}
\item \textcolor{blue}{ELSE} \textcolor{blue}{set} $x=\frac{b_j-a_j}{2}$ and \textcolor{blue}{go to} \textcolor{cyan}{\#}
\item \textcolor{purple}{set} $x_0=x$
\end{Bitemize}
}
\end{Bdescription}
\end{frame}


\begin{frame}

\frametitle{Ideas:}

\textcolor{green}{Hopefully} we have 
$\begin{matrix}
  \textcolor{blue}{x_{0}^{1}}, L(\textcolor{blue}{x_{0}^{1}}), L(L(\textcolor{blue}{x_{0}^{1}})),\dots \leadsto \lambda_1 \\
  \\
  \textcolor{blue}{x_{0}^{2}}, L(\textcolor{blue}{x_{0}^{2}}), L(L(\textcolor{blue}{x_{0}^{2}})),\dots \leadsto \lambda_2 \\
  \\
  \textcolor{cyan}{x_{0}^{3}}, L(\textcolor{cyan}{x_{0}^{3}}), L(L(\textcolor{cyan}{x_{0}^{3}})),\dots \leadsto \lambda_3 \\
  \\
  \textcolor{cyan}{x_{0}^{4}}, L(\textcolor{cyan}{x_{0}^{4}}), L(L(\textcolor{cyan}{x_{0}^{4}})),\dots \leadsto \lambda_4
\end{matrix}$ 

\end{frame}

\begin{frame}
\frametitle{Split}

Consider $(\hat T, \hat S)$ with

\begin{align*}
 \hat T &= \begin{pmatrix} \textcolor{blue}{T_{0}} & 0\\ 0 & \textcolor{cyan}{T_{1}} \end{pmatrix}\\
 \hat S &= \begin{pmatrix} \textcolor{blue}{S_{0}} & 0\\ 0 & \textcolor{cyan}{S_{1}} \end{pmatrix}\\
\end{align*}

with $\textcolor{blue}{T_0}, \textcolor{cyan}{T_1}, \textcolor{blue}{S_0}, \textcolor{cyan}{S_1}$ symmetric tridiagonal, and let be

\begin{equation*}
  \hat\lambda_1 \le \hat\lambda_2 \le \dots \le \hat\lambda_n
\end{equation*}

eigenvalues of $(\hat T, \hat S)$, they are what we call $\mu_1,\dots,\mu_n$.

\end{frame}

\begin{frame}[label=BeforeInterlacing]
\frametitle{Split}

\begin{te}[A sort of ``interlacing'' with \hyperlink{Interlacing}{\beamergotobutton{proof}}]

\begin{align*}
  -\infty < &\lambda_1 \le \hat\lambda_1 \\
  \hat\lambda_{i-1} \le &\lambda_i \le \hat\lambda_{i+1} \\
  \hat\lambda_n \le &\lambda_n < \infty
\end{align*}

with $i=2,3,\dots,n-1$.

\end{te}

\begin{os}
It's possible that

\begin{tikzpicture}
  \uncover<1>{
    \draw[->] (-2,0) -- (9,0); 
    \node[circle, fill=black!1, label=above:$\lambda_{1}$] at (-1,0) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{1}$] at (1,0) {};
    \node[circle, fill=black!1, label=above:$\lambda_{2}$] at (3.5,0) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{3}$] at (6.5,0) {};
    %%%
    \draw[->] (-2,-1) -- (9,-1); 
    \node[circle, fill=black!1, label=above:$\hat\lambda_{2}$] at (2.5,-1) {};
    \node[circle, fill=black!1, label=above:$\lambda_{3}$] at (5,-1) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{4}$] at (8,-1) {};
  }
  \uncover<2,3>{
    \draw[->] (-2,-.5) -- (9,-.5); 
    \node[circle, fill=black!1, label=above:$\lambda_{1}$] at (-1,-.5) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{1}$] at (1,-.5) {};
    \node[circle, fill=black!1, label=above:$\lambda_{2}$] at (3.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{3}$] at (6.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{2}$] at (2.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\lambda_{3}$] at (5,-.5) {};
    \node[circle, fill=black!1, label=above:$\hat\lambda_{4}$] at (8,-.5) {};
  }
  \uncover<3>{
    \draw[red] (3.25,.5) rectangle (5.5,-1);
    }
\end{tikzpicture}


\end{os}

\end{frame}

\begin{frame}
\frametitle{Split}

\begin{os}
  Our method is \textcolor{blue}{monotonic}
\end{os}

\begin{tikzpicture}
\draw[->] (-2,-.5) -- (9,-.5); 
\node[circle, fill=black!1, label=above:$\lambda_{1}$] at (-1,-.5) {};
\node[circle, fill=black!1, label=above:$\hat\lambda_{1}$] at (1,-.5) {};
\node[circle, fill=black!1, label=above:$\lambda_{2}$] at (3.5,-.5) {};
\node[circle, fill=black!1, label=above:$\hat\lambda_{3}$] at (6.5,-.5) {};
\node[circle, fill=black!1, label=above:$\hat\lambda_{2}$] at (2.5,-.5) {};
\node[circle, fill=black!1, label=above:$\lambda_{3}$] at (5,-.5) {};
\node[circle, fill=black!1, label=above:$\hat\lambda_{4}$] at (8,-.5) {};
\draw[green,->] (2.5,.5) -- (3.75,.5);
\draw[green,->] (6.75,.5) -- (5,.5);
\draw[red,->] (2.5,-1) -- (5.25,-1);
\end{tikzpicture}

\pause

We can reach $\lambda_2$ only from $\hat\lambda_2$, moving from left to right (and similar $\lambda_3$ only from $\hat\lambda_3$, moving from right to left).

\pause

If $| \lambda_2-\lambda_3 | \le 10^{-14}$ we can have troubles.

\pause

\textcolor{green}{Luckily} we also have a \emph{multiplicity estimator} (called EstMlt) that works only with $\hat\lambda_1,\dots,\hat\lambda_n$. 

\pause 

If $mlt=2$ then we consider $\lambda_2=\lambda_3$, i.e. we said that $\lambda_2$ has multiplicity $2$.   

\end{frame}

\begin{frame}

  \frametitle{EstMlt}

We have $j,x,\text{ sgn} \Big( -\frac{f^{`}(x)}{f(x)} \Big)$ and $\hat\lambda_1,\dots,\hat\lambda_n$ as \emph{INPUT}.

  \begin{Bdescription}
  \item [Pseudocode:]
    \fbox{\setlength{\itemsep}{0pt}%
      \begin{Bitemize}[t]
      \item $mlt=1$
      \item \textcolor{blue}{do} $k=1,\dots$
      \item $m = j + k \text{ sgn} \Big( -\frac{f^{`}(x)}{f(x)} \Big)$
      \item \textcolor{blue}{if} $m \le 0$ \textcolor{blue}{then}
      \item \textcolor{red}{something goes wrong}
      \item \textcolor{blue}{set} $mlt=1$
      \item \textcolor{blue}{go to} \textcolor{cyan}{\#}
      \item \textcolor{blue}{end if}
      \item \textcolor{blue}{if} $ | \hat\lambda_j - \hat\lambda_m | \le 0.01 | \hat\lambda_j - x | $ \textcolor{blue}{then}
      \item $ mlt = mlt + 1$
      \item \textcolor{blue}{else} \textcolor{green}{go to} \textcolor{cyan}{\#} 
      \item \textcolor{blue}{end if}
      \item \textcolor{blue}{end do}
      \item \textcolor{cyan}{\#} \textcolor{blue}{stop}
    \end{Bitemize}}
    \end{Bdescription}

\end{frame}

\section{Dynamic programming}

\begin{frame}
\frametitle{Dynamic programming}

\begin{Bdescription}
  \item [We want:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Fast and secure iterative method.
  \item Starting points for our method.
  \item Scalability.
  \end{Bitemize}}
  
  \item [We have:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Laguerre's method.
  \item Cuppen's divide and conquer method.
  \item Symmetric tridiagonal matrices.
  \end{Bitemize}}

  \item [We add:]
  \fbox{\setlength{\itemsep}{0pt}%
  \begin{Bitemize}[t]
  \item Unreducible condition.
  \item \textcolor{blue}{Dynamic programming (Bottom-up)}.
  \item Efficient matrix storing.
  \end{Bitemize}}
\end{Bdescription}
\end{frame}

\begin{frame}
  \frametitle{Dynamic programming}

  The author's point of view is \textcolor{blue}{parallel computating}.

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/ParallelComputing_Broadcast_Operation.jpg}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

\end{frame}


\begin{frame}
  \frametitle{Dynamic programming}
  My point of view is \textcolor{blue}{sequential computating}.

  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{images/SequentialComputing.jpg}
    %\caption{$*$= Laguerre's iterations, $+$= bisections}
  \end{figure}

\end{frame}

\begin{frame}
  \frametitle{Dynamic programming}

  Instead of \textcolor{blue}{recurtion} I chose \textcolor{blue}{dynamic programming}, \emph{i.e.} \\ ``solving complex problems by breaking them down into simpler subproblems. [...] In general, to solve a given problem, we need to solve different parts of the problem (subproblems), then combine the solutions of the subproblems to reach an overall solution.'' \\ (cit. Wikipedia)

  \pause

  If $\textcolor{blue}{n=2^k}$, to compute eigenvalues of $(T,S)$ we use $(\hat T, \hat S)$, that use $(\hat{\hat T}, \hat{\hat S})$, that use $(\hat{\hat{\hat T}}, \hat{\hat{\hat S}})$, $\dots$

  \pause

  There is a natural \textcolor{blue}{binary tree structure}.

\end{frame}

\begin{frame}
  \frametitle{Dynamic programming}

  We can 

  \begin{itemize}

    \item compute eigenvalues for all the pencils $2\times 2$ ( they are $2^{k-1}$)
    \item compute eigenvalues for all the pencils $4\times 4$ ( they are $2^{k-2}$)
    \item $\vdots$
    \item compute eigenvalues for all the pencils $\frac{n}{2}\times \frac{n}{2}$ ( they are $2$)
    \item compute eigenvalues of $(T,S)$

  \end{itemize}

  \pause

  This is a ``Bottom-up approach'' because we start with dimension $2$ and finish with dimension $n$.

\end{frame}

\begin{frame}

  \frametitle{Dynamic programming}
  
  \emph{e.g.} $n=16$ 

  \tikzstyle{level 1}=[sibling angle=60]
  \tikzstyle{level 2}=[sibling angle=45]
  \tikzstyle{level 3}=[sibling angle=30]
  \tikzstyle{every node}=[fill]
  \tikzstyle{edge from parent}=[snake=expanding waves,segment length=1mm,segment angle=10,draw]
  \begin{tikzpicture}[grow cyclic,shape=circle,very thick,level distance=13mm,cap=round]
    \node {} child [color=\A] foreach \A in {green,blue}
          { node {} child [color=\A!50!\B] foreach \B in {green,blue}
            { node {}
              child [color=\A!50!\B!50!\C] foreach \C in {green,blue}
              { node {} }
            }
          };
  \end{tikzpicture}
  
  We start from leaves ($\text{dim=}2$) and finish with the root ($\text{dim=}16$)

\end{frame}

\begin{frame}
  \frametitle{Dynamic programming}

  \begin{Bdescription}
  \item [Code:]
    \fbox{\setlength{\itemsep}{0pt}%
      \begin{Bitemize}[t]
        \item \textcolor{blue}{WHILE} $\text{dim} \le n$          
        \item \textcolor{blue}{DO} $k=0, \frac{n}{\text{dim}} - 1$

        \item \textcolor{blue}{set} $Tstart = 1 + k \text{dim}$ \textcolor{blue}{and} $Tend = (1 + k) \text{dim}$
        \item \textcolor{blue}{set} $Sstart = 1 + k \text{dim}$ \textcolor{blue}{and} $Send = (1 + k) \text{dim}$

        \item \textcolor{blue}{IF} $\text{dim}=2$ 
        \item \textcolor{blue}{THEN}
        \item \textcolor{green}{explicit calculation}
        \item \textcolor{blue}{ELSE}
        \item \textcolor{blue}{search eigenvalues of} 
        \item $\textcolor{cyan}{(T(Tstart\dots Tend,0\dots 1),S(Sstart\dots Send,0\dots 1))}$
        \item \textcolor{blue}{knowing eigenvalues of}
        \item $\textcolor{green}{(T(Tstart\dots\frac{Tend}{2},0\dots 1),S(Sstart\dots\frac{Send}{2},0\dots 1))}$ 
        \item \textcolor{blue}{and} 
        \item $\textcolor{green}{(T(\frac{Tend}{2}+1\dots Tend,0\dots 1),S(\frac{Send}{2}+1,0\dots 1))}$
        \item \textcolor{blue}{END DO}
      
    \end{Bitemize}}
  \end{Bdescription}
  
\end{frame}

\section{Othder thinks}

\begin{frame}
  \frametitle{Instead of all eigenvalues...}

  ...We can search \textcolor{blue}{only} eigenvalues in one particular interval of real line.

  \pause

  \emph{e.g.} we are interested in $[0,10^{-16}]$ or $[10^{3},10^{8}]$ or we want to use \emph{Gershgorin theorems} to isolate particolar eigenvalues.

  \pause

  ...If \textcolor{blue}{also} $T$ is \emph{definite} we can search eigenvalues in $[1,\infty]$ using our method with (S,T) and $\lambda_j=\frac{1}{\mu_j}$.

\end{frame}

\begin{frame}
  \frametitle{``Real world'' matrices}

  Consider \emph{piecewise linear finite element discretization of} the \textcolor{blue}{Sturm-Liouville problem}

  \begin{equation*}
    - \frac{d}{d x}\Big( p(x) \frac{d u}{d x} \Big) + q(x) u = \lambda u
  \end{equation*}

  where $u=u(x),0<x<\pi$ and $u(0)=u^{'}(\pi)=0$ and $p(x)=1,q(x)=6$ ( $h=\frac{1}{n+1}$). \\
  We obtain\symbolfootnote[1]{authors doesn't report $(T,S)$}
  
  \begin{align*}
    t_{k,k} &= -6 h (2 k^2 -2 k -1)\\
    t_{k,k+1} &= -\frac{1}{h} + h\\
    s_{k,k} &= \frac{4 h}{6}\\
    s_{k,k+1} &= \frac{h}{6}
  \end{align*}

\end{frame}

\begin{frame}
  \frametitle{``Real world'' matrices}

  

\end{frame}

\begin{frame}
  Thank you.
\end{frame}

\section{Appendices}

\begin{frame}[label=LagProof]
  \frametitle{Appendix A: proof of Laguerre's convergence}

  According to \cite[p.444]{bookWilkinson} we can write 

  \begin{align*}
    x_{\pm}^{(k+1)} &= x_{\pm}^{(k)} - \frac{n f}{f^{'} \pm H^{\frac{1}{2}}} \\
    H &= (n-1)^2 (f^{'})^2 -n(n-1)f f^{''}
  \end{align*}

  If we \textcolor{green}{choose the sign} so that the $| f^{'} \textcolor{green}{\pm} H^{\frac{1}{2}} |$ has the larger absolute value then we can approx $x_{\pm}^{(k+1)} - \lambda_m$ as

  \begin{align*}
    x_{\pm}^{(k+1)} - \lambda_m &\approx \frac{1}{2}(x_{\pm}^{(k)} - \lambda_m)^3 \frac{(n-1)\Sigma_2^{'} - (\Sigma_1^{'})^2}{n-1}\\
    \Sigma_2^{'} &= \sum_{i\ne n} \frac{1}{(\lambda_m - \lambda_i)^2}\\
    \Sigma_1^{'} &= \sum_{i\ne n} \frac{1}{\lambda_m - \lambda_i}
  \end{align*}

\end{frame}

\begin{frame}
  \frametitle{Appendix A: proof of Laguerre's convergence}

  So we have \textcolor{blue}{convergence} and $\textcolor{green}{x_{\pm}^{(k+1)} - \lambda_m} \textcolor{blue}{\approx} \text{ number } \textcolor{green}{(x_{\pm}^{(k)} - \lambda_m)^3}$ tell us that the convergence is \textcolor{blue}{cubic.}

  \hyperlink{BeforeLagProof}{\beamergotobutton{back}}
\end{frame}

\begin{frame}[label=SturmSequence]
  \frametitle{Appendix B: proof of property about Sturm sequence}

  
  \hyperlink{BeforeSturmSequence}{\beamergotobutton{back}}

\end{frame}

\begin{frame}[label=Interlacing]
  \frametitle{Appendix B: interlacing}

  \begin{de}
    For $\alpha\in[0,1]$ we define the pencil $\big( T(\alpha), S(\alpha) \big) := \big( (1-\alpha)\hat T + \alpha T, (1-\alpha)\hat S + \alpha S \big)$.
  \end{de}

  \begin{lem}
    $\big( T(\alpha), S(\alpha) \big)$ is a \emph{symmetric definite} pencil for each $\alpha\in[0,1]$.
  \end{lem}

  Calling $\lambda_1(\alpha)\le \lambda_2(\alpha)\le \dots \le \lambda_n(\alpha)$ the $n$ real eigenvalues of the pencil  $\big( T(\alpha), S(\alpha) \big)$ we have

  \begin{lem}
    Each $\lambda_i(\alpha)$ is a continuous function of $\alpha\in[0,1]$.
  \end{lem}

\end{frame}

\begin{frame}
  \frametitle{Appendix B: interlacing}

  \begin{te}[A sort of ``interlacing'']
    \begin{align*}
      -\infty < &\lambda_1 \le \hat\lambda_1 \\
      \hat\lambda_{i-1} \le &\lambda_i \le \hat\lambda_{i+1} \\
      \hat\lambda_n \le &\lambda_n < \infty
    \end{align*}

    with $i=2,3,\dots,n-1$.
  \end{te}

  \pause

  %\begin{proof}

  \emph{Classic interlacing} still works for $-\infty < \lambda_1 \le \hat\lambda_1$ and for $\hat\lambda_n \le \lambda_n < \infty$.

  \pause

  We have to proove that $\textcolor{blue}{\lambda_i \ge \hat\lambda_{i-1}}$ (and similar $\lambda_i \le \hat\lambda_{i+1}$).

\end{frame}

\begin{frame}
  \frametitle{Appendix B: interlacing}

  (\textcolor{blue}{Proof by contradiction}) if we consider $\textcolor{red}{\lambda_i< \hat\lambda_{i-1}}$ for some $i\in\{2,3,\dots,n-1 \}$ (that, in our new writing, is $\textcolor{red}{\lambda_i(1)<\lambda_{i-1}(0)}$ because all $\lambda_j(1)$ are eigenvalues of $(T,S)$ and all $\lambda_j(0)$ are eigenvalues of $(\hat T, \hat S)$) then

  \pause

  \begin{tikzpicture}
    \draw[->] (-5,-.5) -- (5,-.5); 
    \node[circle, fill=black!1, label=below:$\lambda_{i-1}(1)$] at (-3.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\lambda_{i}(1)$] at (-2,-.5) {};
    \node[circle, fill=black!1, label=below:$\lambda_{i-1}(0)$] at (1.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\lambda_{i}(0)$] at (4,-.5) {};

    %\draw[green,->] (2.5,.5) -- (3.75,.5);
    %\draw[green,->] (6.75,.5) -- (5,.5);
    %\draw[red,->] (2.5,-1) -- (5.25,-1);
  \end{tikzpicture}

  \pause

  in symbols: $\lambda_{i-1}(1) \le \lambda_i(1) < \lambda_{i-1}(0) \le \lambda_i(0)$. 

  \pause
  
  \textcolor{blue}{For all} $\tilde\lambda\in [\lambda_i(1),\lambda_{i-1}(0)]$ we can find $\alpha_i, \alpha_{i-1}$ such as $\tilde\lambda=\lambda_i(\alpha_i)=\lambda_{i-1}(\alpha_{i-1})$.


\end{frame}


\begin{frame}
  \frametitle{Appendix B: interlacing}
  \begin{tikzpicture}
    \draw[->] (-5,-.5) -- (5,-.5); 
    \node[circle, fill=black!1, label=below:$\lambda_{i-1}(1)$] at (-3.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\lambda_{i}(1)$] at (-2,-.5) {};
    \node[circle, fill=black!1, label=below:$\lambda_{i-1}(0)$] at (1.5,-.5) {};
    \node[circle, fill=black!1, label=above:$\lambda_{i}(0)$] at (4,-.5) {};

    \uncover <2> {
      \node[draw=none, label=center:$\textcolor{red}{\tilde\lambda}$] at (0,-.5) {}; 
    }
    \uncover <3> {
      \draw[red,<-] (-2.6,-1) -- (1,-1);
      \node[draw=none, label=below:$\textcolor{red}{\lambda_{i-1}(\alpha_{i-1})}$] at (0,0) {};
    }
    \uncover <4> {
      \draw[red,<-] (-1.40,0.15) -- (3.75,0.15);
      \node[draw=none, label=below:$\textcolor{red}{\lambda_{i}(\alpha_{i})}$] at (0,0) {};
    }
  \end{tikzpicture}

\end{frame}


\begin{frame}
  \frametitle{Appendix B: interlacing}

  $H(\alpha,\lambda) := det[T(\alpha)-\lambda S(\alpha)] =$

  \begin{equation*}
    \begin{bmatrix}  
     & \ddots & \ddots & & & \\
      & \ddots & t_{k,k}-\lambda s_{k,k} & \alpha(t_{k,k+1}-s_{k,k+1}) & & \\
      & & \alpha(t_{k,k+1}-s_{k,k+1}) & t_{k+1,k+1}-\lambda s_{k+1,k+1} & \ddots \\
      & & & \ddots & \ddots
    \end{bmatrix}
  \end{equation*}


\pause

 So 

  \begin{equation*}
    H(\alpha,\lambda) = p(\lambda) + \alpha^2 q(\lambda)
  \end{equation*}

  with $p,q$ polynomials.

\end{frame}

\begin{frame}
  \frametitle{Appendix B: interlacing}

  If $q(\tilde\lambda)\ne 0$ then $\tilde\alpha= + \sqrt{H(\tilde\alpha,\tilde\lambda)-\frac{p(\tilde\lambda)}{q(\tilde\lambda)}}\in[0,1]$.\\
  only \textcolor{red}{one} solution in $\alpha$.

  \pause

  But we have, \textcolor{blue}{for all} $\tilde\lambda$, \textcolor{red}{two} solution in $\alpha$, named $\textcolor{red}{\alpha_i}$ and $\textcolor{red}{\alpha_{i-1}}$. 

  \pause

  Then $q(\lambda)=0$ for all $\tilde\lambda$. \\
  We have $\tilde\lambda$ eigenvalue of $(\hat T, \hat S)$, \textcolor{red}{for all} $\tilde\lambda$ and $(\hat T, \hat S)$ have exactly $n$ eigenvalues.

  \pause

  \textcolor{blue}{conctraddiction}
 

  \hyperlink{BeforeInterlacing}{\beamergotobutton{back}}

\end{frame}


\begin{frame}[label=CodeIf]
  \frametitle{Appendix D: code}

%  \begin{lstlisting}[style=fortranSlide, caption={how to find $[a_j,b_j]$}]
%    if (kappa+1 < j) then
%    x = (aj+bj)/2.d0
%    GOTO 100
%    end if
%    if (j < kappa) then
%    x = (aj+bj)/2.d0
%    GOTO 100
%    end if
%    if (kappa >= j .AND. segno >= 0) then
%    x = (aj+bj)/2.d0
%    GOTO 100
%    end if
%    \end{lstlisting}
\end{frame}


\begin{frame}
  \frametitle{Appendix D: code}

%  \begin{lstlisting}[style=fortranSlide, caption={how to find $[a_j,b_j]$}]
%    if (kappa < j .AND. segno < 0) then
%    x = (aj+bj)/2.d0
%    GOTO 100
%    end if
%    if (kappa == 0 .AND. segno <0) then
%    x = (aj+bj)/2.d0
%    GOTO 100
%    end if
%    if (kappa == dim .AND. segno >=0) then
%    x = (aj+bj)/2.d0
%    GOTO 100
%    end if
%  \end{lstlisting}
  \hyperlink{BeforeCodeIf}{\beamergotobutton{back}}
\end{frame}


\begin{frame}
  \bibliography{bibliography}
  \bibliographystyle{alpha}
\end{frame}

\frame{
\begin{center}
Grazie (ancora) per l'attenzione.
\end{center}
}



%%%
%%%
%%%
\end{document}
